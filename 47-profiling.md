# 47 - Profiling and Performance

> Measuring and optimizing Go application performance.

---

## ğŸ“Œ What You'll Learn

- CPU profiling
- Memory profiling
- Trace analysis
- Benchmark-driven optimization
- Common performance tips

---

## ğŸ“Š pprof Basics

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                 â”‚
â”‚  GO PROFILING TOOLS                                             â”‚
â”‚                                                                 â”‚
â”‚  pprof:                                                         â”‚
â”‚  â€¢ CPU profiling (where time is spent)                          â”‚
â”‚  â€¢ Memory profiling (allocations)                               â”‚
â”‚  â€¢ Goroutine profiling (blocking)                               â”‚
â”‚                                                                 â”‚
â”‚  trace:                                                         â”‚
â”‚  â€¢ Execution tracer (goroutine scheduling)                      â”‚
â”‚  â€¢ GC events                                                    â”‚
â”‚  â€¢ System calls                                                 â”‚
â”‚                                                                 â”‚
â”‚  PROFILING WORKFLOW:                                            â”‚
â”‚  1. Collect profile data                                        â”‚
â”‚  2. Analyze with go tool pprof                                  â”‚
â”‚  3. Identify hotspots                                           â”‚
â”‚  4. Optimize                                                    â”‚
â”‚  5. Measure again (verify improvement)                          â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”¥ CPU Profiling

```go
// cpu_profile.go
package main

import (
    "fmt"
    "os"
    "runtime/pprof"
    "time"
)

func heavyComputation() {
    result := 0
    for i := 0; i < 100000000; i++ {
        result += i * i
    }
    _ = result
}

func main() {
    // Create CPU profile file
    f, err := os.Create("cpu.prof")
    if err != nil {
        panic(err)
    }
    defer f.Close()
    
    // Start CPU profiling
    pprof.StartCPUProfile(f)
    defer pprof.StopCPUProfile()
    
    // Your application code
    fmt.Println("Running heavy computation...")
    start := time.Now()
    heavyComputation()
    fmt.Printf("Done in %v\n", time.Since(start))
}

/*
Run and analyze:
    go run cpu_profile.go
    go tool pprof cpu.prof
    
pprof commands:
    top        - Show top functions by CPU time
    top10      - Top 10 functions
    list func  - Show source code for function
    web        - Open interactive graph in browser
    svg        - Generate SVG graph
*/
```

---

## ğŸ§  Memory Profiling

```go
// memory_profile.go
package main

import (
    "os"
    "runtime"
    "runtime/pprof"
)

func allocateMemory() [][]byte {
    slices := make([][]byte, 1000)
    for i := range slices {
        slices[i] = make([]byte, 10000)  // 10KB each
    }
    return slices
}

func main() {
    // Allocate memory
    data := allocateMemory()
    
    // Force GC
    runtime.GC()
    
    // Create heap profile
    f, _ := os.Create("mem.prof")
    defer f.Close()
    
    pprof.WriteHeapProfile(f)
    
    // Keep data alive
    _ = data
}

/*
Analyze:
    go tool pprof mem.prof
    
Commands:
    top        - Top memory consumers
    allocs     - Show allocations
    inuse      - Show in-use memory
*/
```

---

## ğŸŒ HTTP Server Profiling

```go
// http_pprof.go
package main

import (
    "fmt"
    "net/http"
    _ "net/http/pprof"  // Import for side effects!
)

func main() {
    // pprof endpoints automatically registered:
    // /debug/pprof/
    // /debug/pprof/cmdline
    // /debug/pprof/profile
    // /debug/pprof/symbol
    // /debug/pprof/trace
    // /debug/pprof/heap
    // /debug/pprof/goroutine
    
    http.HandleFunc("/", func(w http.ResponseWriter, r *http.Request) {
        fmt.Fprintf(w, "Hello!")
    })
    
    fmt.Println("Server running on :8080")
    fmt.Println("pprof at http://localhost:8080/debug/pprof/")
    http.ListenAndServe(":8080", nil)
}

/*
Profile running server:
    # CPU profile (30 seconds)
    go tool pprof http://localhost:8080/debug/pprof/profile?seconds=30
    
    # Heap profile
    go tool pprof http://localhost:8080/debug/pprof/heap
    
    # Goroutine profile
    go tool pprof http://localhost:8080/debug/pprof/goroutine
*/
```

---

## ğŸ“ˆ Benchmark Profiling

```go
// bench_test.go
package main

import "testing"

func BenchmarkStringConcat(b *testing.B) {
    for i := 0; i < b.N; i++ {
        s := ""
        for j := 0; j < 100; j++ {
            s += "x"
        }
    }
}

/*
Run with profiling:
    go test -bench=. -cpuprofile=cpu.prof
    go test -bench=. -memprofile=mem.prof
    go test -bench=. -benchmem
    
Analyze:
    go tool pprof cpu.prof
*/
```

---

## âš¡ Performance Tips

```go
// performance_tips.go
package main

import (
    "bytes"
    "fmt"
    "strings"
)

func main() {
    fmt.Println("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
    fmt.Println("â•‘           PERFORMANCE TIPS                                â•‘")
    fmt.Println("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
    
    // 1. String concatenation
    fmt.Println("\nğŸ“Š String Concatenation:")
    fmt.Println("   âŒ Slow: s += \"x\" (creates new string each time)")
    fmt.Println("   âœ… Fast: strings.Builder or bytes.Buffer")
    
    var builder strings.Builder
    for i := 0; i < 100; i++ {
        builder.WriteString("x")
    }
    _ = builder.String()
    
    // 2. Pre-allocate slices
    fmt.Println("\nğŸ“Š Slice Pre-allocation:")
    fmt.Println("   âŒ Slow: append grows slice multiple times")
    fmt.Println("   âœ… Fast: make([]T, 0, expectedSize)")
    
    data := make([]int, 0, 1000)  // Pre-allocate capacity
    for i := 0; i < 1000; i++ {
        data = append(data, i)
    }
    
    // 3. Avoid interface{} when possible
    fmt.Println("\nğŸ“Š Avoid interface{}:")
    fmt.Println("   âŒ Slow: func process(v interface{})")
    fmt.Println("   âœ… Fast: func process(v int) or generics")
    
    // 4. sync.Pool for frequently allocated objects
    fmt.Println("\nğŸ“Š sync.Pool:")
    fmt.Println("   Use for frequently allocated/deallocated objects")
    fmt.Println("   Reduces GC pressure")
    
    // 5. Avoid copying large structs
    fmt.Println("\nğŸ“Š Pointer vs Value:")
    fmt.Println("   Large structs: pass by pointer")
    fmt.Println("   Small structs (<64 bytes): pass by value")
    
    // 6. Use buffered I/O
    fmt.Println("\nğŸ“Š Buffered I/O:")
    fmt.Println("   Use bufio.Reader/Writer for file/network I/O")
    
    _ = bytes.Buffer{}  // Suppress unused warning
}
```

---

## ğŸ¯ Key Takeaways

1. **pprof** for CPU and memory profiling
2. **net/http/pprof** for HTTP servers
3. **go tool pprof** to analyze profiles
4. **Benchmark before optimizing**
5. **Pre-allocate** slices and maps
6. **strings.Builder** for string concatenation
7. **sync.Pool** for object reuse

---

## â¡ï¸ Next Steps

**Next Topic:** [48 - Build Constraints](./48-build-constraints.md)

