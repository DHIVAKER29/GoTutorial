# 29 - Goroutines & Concurrency Fundamentals

> Understanding concurrency, parallelism, the Go scheduler, and goroutines in depth.

---

## ğŸ“Œ What You'll Learn

- Concurrency vs Parallelism (the critical difference!)
- Processes, Threads, and Goroutines
- How the Go Runtime Scheduler works (M:N scheduling)
- GOMAXPROCS and controlling parallelism
- Creating and managing goroutines
- Common gotchas and best practices
- Race conditions introduction

---

## ğŸ§  Concurrency vs Parallelism

### The Most Misunderstood Concept

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                 â”‚
â”‚  CONCURRENCY â‰  PARALLELISM                                      â”‚
â”‚                                                                 â”‚
â”‚  CONCURRENCY = "Dealing with many things at once"               â”‚
â”‚  PARALLELISM = "Doing many things at once"                      â”‚
â”‚                                                                 â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€   â”‚
â”‚                                                                 â”‚
â”‚  REAL WORLD ANALOGY: A Coffee Shop                              â”‚
â”‚                                                                 â”‚
â”‚  CONCURRENCY (1 barista, multiple orders):                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                                                         â”‚   â”‚
â”‚  â”‚  1 Barista handles multiple orders by SWITCHING:        â”‚   â”‚
â”‚  â”‚                                                         â”‚   â”‚
â”‚  â”‚  â€¢ Take order A                                         â”‚   â”‚
â”‚  â”‚  â€¢ Start brewing A, while waiting...                    â”‚   â”‚
â”‚  â”‚  â€¢ Take order B                                         â”‚   â”‚
â”‚  â”‚  â€¢ A is done, serve A                                   â”‚   â”‚
â”‚  â”‚  â€¢ Start brewing B, while waiting...                    â”‚   â”‚
â”‚  â”‚  â€¢ Take order C                                         â”‚   â”‚
â”‚  â”‚  â€¢ B is done, serve B                                   â”‚   â”‚
â”‚  â”‚  ... and so on                                          â”‚   â”‚
â”‚  â”‚                                                         â”‚   â”‚
â”‚  â”‚  ONE person, managing MULTIPLE tasks                    â”‚   â”‚
â”‚  â”‚  Tasks INTERLEAVE but don't run SIMULTANEOUSLY          â”‚   â”‚
â”‚  â”‚                                                         â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                 â”‚
â”‚  PARALLELISM (3 baristas, multiple orders):                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                                                         â”‚   â”‚
â”‚  â”‚  3 Baristas each handle different orders SIMULTANEOUSLY:â”‚   â”‚
â”‚  â”‚                                                         â”‚   â”‚
â”‚  â”‚  Barista 1: Making order A â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€            â”‚   â”‚
â”‚  â”‚  Barista 2: Making order B â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€            â”‚   â”‚
â”‚  â”‚  Barista 3: Making order C â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€            â”‚   â”‚
â”‚  â”‚                                                         â”‚   â”‚
â”‚  â”‚  THREE people, doing work AT THE SAME TIME              â”‚   â”‚
â”‚  â”‚  Tasks run SIMULTANEOUSLY on multiple CPUs              â”‚   â”‚
â”‚  â”‚                                                         â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                 â”‚
â”‚  KEY INSIGHT:                                                   â”‚
â”‚  â€¢ CONCURRENCY is about STRUCTURE (code organization)           â”‚
â”‚  â€¢ PARALLELISM is about EXECUTION (hardware)                    â”‚
â”‚  â€¢ You can have concurrency WITHOUT parallelism (1 CPU)         â”‚
â”‚  â€¢ Go gives you concurrency; runtime decides parallelism        â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### In Programming Terms

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                 â”‚
â”‚  SINGLE CORE (Concurrency only):                                â”‚
â”‚                                                                 â”‚
â”‚  Time â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º           â”‚
â”‚  CPU:  [Task A][Task B][Task A][Task C][Task B][Task A]         â”‚
â”‚        â†‘                                                        â”‚
â”‚        Tasks take turns (time-slicing)                          â”‚
â”‚        Only ONE task runs at any moment                         â”‚
â”‚                                                                 â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€   â”‚
â”‚                                                                 â”‚
â”‚  MULTI CORE (Parallelism possible):                             â”‚
â”‚                                                                 â”‚
â”‚  Time â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º           â”‚
â”‚  CPU1: [Task A][Task A][Task A][Task A]                         â”‚
â”‚  CPU2: [Task B][Task B][Task B][Task B]                         â”‚
â”‚  CPU3: [Task C][Task C][Task C][Task C]                         â”‚
â”‚        â†‘                                                        â”‚
â”‚        Multiple tasks run SIMULTANEOUSLY                        â”‚
â”‚        True parallelism on multiple cores                       â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”„ Processes vs Threads vs Goroutines

### The Evolution

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                 â”‚
â”‚  PROCESS (Heaviest)                                             â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Own memory space (isolated)                            â”‚   â”‚
â”‚  â”‚  Own file descriptors, security context                 â”‚   â”‚
â”‚  â”‚  Created via fork() - expensive!                        â”‚   â”‚
â”‚  â”‚  Communication via IPC (pipes, sockets)                 â”‚   â”‚
â”‚  â”‚  Crash doesn't affect other processes                   â”‚   â”‚
â”‚  â”‚                                                         â”‚   â”‚
â”‚  â”‚  Memory: ~10MB+ overhead                                â”‚   â”‚
â”‚  â”‚  Creation: Milliseconds                                 â”‚   â”‚
â”‚  â”‚  Context switch: ~1000+ microseconds                    â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                 â”‚
â”‚  THREAD (Medium)                                                â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Share process memory (same address space)              â”‚   â”‚
â”‚  â”‚  Own stack (~1-8MB fixed on Linux)                      â”‚   â”‚
â”‚  â”‚  Managed by OS kernel                                   â”‚   â”‚
â”‚  â”‚  Communication via shared memory                        â”‚   â”‚
â”‚  â”‚  Crash can affect entire process                        â”‚   â”‚
â”‚  â”‚                                                         â”‚   â”‚
â”‚  â”‚  Memory: ~1-8MB stack                                   â”‚   â”‚
â”‚  â”‚  Creation: ~100 microseconds                            â”‚   â”‚
â”‚  â”‚  Context switch: ~1-10 microseconds                     â”‚   â”‚
â”‚  â”‚  Max: ~10,000 threads per process                       â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                 â”‚
â”‚  GOROUTINE (Lightest)                                           â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Share process memory                                   â”‚   â”‚
â”‚  â”‚  Own stack (~2KB initial, grows dynamically!)           â”‚   â”‚
â”‚  â”‚  Managed by Go runtime (NOT OS)                         â”‚   â”‚
â”‚  â”‚  Communication via channels (or shared memory)          â”‚   â”‚
â”‚  â”‚  Multiplexed onto OS threads (M:N scheduling)           â”‚   â”‚
â”‚  â”‚                                                         â”‚   â”‚
â”‚  â”‚  Memory: ~2KB initial (grows to MB if needed)           â”‚   â”‚
â”‚  â”‚  Creation: ~0.3 microseconds                            â”‚   â”‚
â”‚  â”‚  Context switch: ~0.2 microseconds                      â”‚   â”‚
â”‚  â”‚  Max: MILLIONS of goroutines!                           â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                 â”‚
â”‚  COMPARISON TABLE:                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚                â”‚ Process   â”‚ Thread    â”‚ Goroutine     â”‚    â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â”‚
â”‚  â”‚ Stack size     â”‚ N/A       â”‚ 1-8 MB    â”‚ 2 KB (grows)  â”‚    â”‚
â”‚  â”‚ Creation time  â”‚ ~100ms    â”‚ ~100Âµs    â”‚ ~0.3Âµs        â”‚    â”‚
â”‚  â”‚ Context switch â”‚ ~1000Âµs   â”‚ ~1-10Âµs   â”‚ ~0.2Âµs        â”‚    â”‚
â”‚  â”‚ Max practical  â”‚ ~100s     â”‚ ~10,000   â”‚ ~1,000,000+   â”‚    â”‚
â”‚  â”‚ Managed by     â”‚ OS        â”‚ OS        â”‚ Go Runtime    â”‚    â”‚
â”‚  â”‚ Scheduling     â”‚ Preemptiveâ”‚ Preemptiveâ”‚ Cooperative*  â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                                 â”‚
â”‚  * Go 1.14+ added preemptive scheduling for goroutines          â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## âš™ï¸ Go Runtime Scheduler (GMP Model)

### Understanding M:N Scheduling

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                 â”‚
â”‚  GO SCHEDULER: GMP MODEL                                        â”‚
â”‚                                                                 â”‚
â”‚  G = Goroutine (the work to be done)                            â”‚
â”‚  M = Machine (OS thread that executes)                          â”‚
â”‚  P = Processor (scheduling context, holds runqueue)             â”‚
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚                                                            â”‚â”‚
â”‚  â”‚     â”Œâ”€â”€â”€â” â”Œâ”€â”€â”€â” â”Œâ”€â”€â”€â” â”Œâ”€â”€â”€â”     Global Run Queue          â”‚â”‚
â”‚  â”‚     â”‚ G â”‚ â”‚ G â”‚ â”‚ G â”‚ â”‚ G â”‚ â—„â”€â”€ (waiting goroutines)      â”‚â”‚
â”‚  â”‚     â””â”€â”€â”€â”˜ â””â”€â”€â”€â”˜ â””â”€â”€â”€â”˜ â””â”€â”€â”€â”˜                                â”‚â”‚
â”‚  â”‚                                                            â”‚â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚â”‚
â”‚  â”‚  â”‚  P0 (Processor 0)              P1 (Processor 1)      â”‚  â”‚â”‚
â”‚  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚  â”‚â”‚
â”‚  â”‚  â”‚  â”‚ Local Run Queue â”‚           â”‚ Local Run Queue â”‚   â”‚  â”‚â”‚
â”‚  â”‚  â”‚  â”‚ â”Œâ”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”   â”‚           â”‚ â”Œâ”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”   â”‚   â”‚  â”‚â”‚
â”‚  â”‚  â”‚  â”‚ â”‚ G â”‚ G â”‚ G â”‚   â”‚           â”‚ â”‚ G â”‚ G â”‚ G â”‚   â”‚   â”‚  â”‚â”‚
â”‚  â”‚  â”‚  â”‚ â””â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”˜   â”‚           â”‚ â””â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”˜   â”‚   â”‚  â”‚â”‚
â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚  â”‚â”‚
â”‚  â”‚  â”‚           â”‚                             â”‚             â”‚  â”‚â”‚
â”‚  â”‚  â”‚           â–¼                             â–¼             â”‚  â”‚â”‚
â”‚  â”‚  â”‚      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚  â”‚â”‚
â”‚  â”‚  â”‚      â”‚ M (OS   â”‚                   â”‚ M (OS   â”‚        â”‚  â”‚â”‚
â”‚  â”‚  â”‚      â”‚ Thread) â”‚                   â”‚ Thread) â”‚        â”‚  â”‚â”‚
â”‚  â”‚  â”‚      â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜                   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜        â”‚  â”‚â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚â”‚
â”‚  â”‚              â”‚                             â”‚                â”‚â”‚
â”‚  â”‚              â–¼                             â–¼                â”‚â”‚
â”‚  â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚â”‚
â”‚  â”‚         â”‚  CPU 0  â”‚                   â”‚  CPU 1  â”‚           â”‚â”‚
â”‚  â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚â”‚
â”‚  â”‚                                                            â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚                                                                 â”‚
â”‚  HOW IT WORKS:                                                  â”‚
â”‚  1. Goroutines (G) are created and added to queues              â”‚
â”‚  2. Processors (P) pick up Gs from their local queue            â”‚
â”‚  3. Machines (M) execute the G that P gives them                â”‚
â”‚  4. Number of Ps = GOMAXPROCS (default = CPU cores)             â”‚
â”‚  5. Ms can be more than Ps (some may be blocked on syscalls)    â”‚
â”‚                                                                 â”‚
â”‚  WORK STEALING:                                                 â”‚
â”‚  â€¢ If P's local queue is empty, steal from other Ps             â”‚
â”‚  â€¢ If all local queues empty, check global queue                â”‚
â”‚  â€¢ Ensures load balancing across all Ps                         â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”§ GOMAXPROCS

```go
// gomaxprocs.go
package main

import (
    "fmt"
    "runtime"
    "sync"
    "time"
)

func main() {
    fmt.Println("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
    fmt.Println("â•‘           GOMAXPROCS - CONTROLLING PARALLELISM            â•‘")
    fmt.Println("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
    
    // Check current values
    fmt.Println("\nğŸ“Š System Information:")
    fmt.Printf("   NumCPU (logical cores): %d\n", runtime.NumCPU())
    fmt.Printf("   GOMAXPROCS (default): %d\n", runtime.GOMAXPROCS(0))
    fmt.Printf("   NumGoroutine (current): %d\n", runtime.NumGoroutine())
    
    // GOMAXPROCS explanation
    fmt.Println("\nğŸ“Š GOMAXPROCS Explained:")
    fmt.Println("   â€¢ Controls max number of OS threads running Go code simultaneously")
    fmt.Println("   â€¢ Default = number of CPU cores (since Go 1.5)")
    fmt.Println("   â€¢ GOMAXPROCS(1) = no parallelism (concurrency only)")
    fmt.Println("   â€¢ GOMAXPROCS(4) = up to 4 goroutines run in parallel")
    
    // Demonstrate difference
    fmt.Println("\nğŸ“Š Experiment: GOMAXPROCS Effect")
    
    // With GOMAXPROCS = 1 (no parallelism)
    fmt.Println("\n   GOMAXPROCS = 1 (sequential on single thread):")
    runtime.GOMAXPROCS(1)
    runWorkers()
    
    // With GOMAXPROCS = NumCPU (max parallelism)
    fmt.Printf("\n   GOMAXPROCS = %d (parallel on multiple cores):\n", runtime.NumCPU())
    runtime.GOMAXPROCS(runtime.NumCPU())
    runWorkers()
    
    // When to change GOMAXPROCS
    fmt.Println("\nğŸ’¡ When to Change GOMAXPROCS:")
    fmt.Println("   â€¢ Usually DON'T - default is optimal")
    fmt.Println("   â€¢ Container limits: may need to match cgroup CPU limit")
    fmt.Println("   â€¢ CPU-bound work: might limit to leave room for GC")
    fmt.Println("   â€¢ Debugging: GOMAXPROCS=1 to simplify race condition debugging")
}

func runWorkers() {
    start := time.Now()
    var wg sync.WaitGroup
    
    for i := 0; i < 4; i++ {
        wg.Add(1)
        go func(id int) {
            defer wg.Done()
            // Simulate CPU work
            sum := 0
            for j := 0; j < 10000000; j++ {
                sum += j
            }
            _ = sum
        }(i)
    }
    
    wg.Wait()
    fmt.Printf("   Completed in: %v\n", time.Since(start))
}
```

**Output:**
```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘           GOMAXPROCS - CONTROLLING PARALLELISM            â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“Š System Information:
   NumCPU (logical cores): 8
   GOMAXPROCS (default): 8
   NumGoroutine (current): 1

ğŸ“Š GOMAXPROCS Explained:
   â€¢ Controls max number of OS threads running Go code simultaneously
   â€¢ Default = number of CPU cores (since Go 1.5)
   â€¢ GOMAXPROCS(1) = no parallelism (concurrency only)
   â€¢ GOMAXPROCS(4) = up to 4 goroutines run in parallel

ğŸ“Š Experiment: GOMAXPROCS Effect

   GOMAXPROCS = 1 (sequential on single thread):
   Completed in: 45.234ms

   GOMAXPROCS = 8 (parallel on multiple cores):
   Completed in: 12.456ms

ğŸ’¡ When to Change GOMAXPROCS:
   â€¢ Usually DON'T - default is optimal
   â€¢ Container limits: may need to match cgroup CPU limit
   â€¢ CPU-bound work: might limit to leave room for GC
   â€¢ Debugging: GOMAXPROCS=1 to simplify race condition debugging
```

---

## ğŸ“ Creating Goroutines - Complete Guide

```go
// goroutines_complete.go
package main

import (
    "fmt"
    "runtime"
    "sync"
    "time"
)

func main() {
    fmt.Println("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
    fmt.Println("â•‘           GOROUTINES - COMPLETE GUIDE                     â•‘")
    fmt.Println("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
    
    // Method 1: Named function
    fmt.Println("\nğŸ“Š Method 1: Named Function")
    var wg sync.WaitGroup
    wg.Add(1)
    go namedFunction(&wg)
    wg.Wait()
    
    // Method 2: Anonymous function
    fmt.Println("\nğŸ“Š Method 2: Anonymous Function")
    wg.Add(1)
    go func() {
        defer wg.Done()
        fmt.Println("   Hello from anonymous function!")
    }()
    wg.Wait()
    
    // Method 3: With parameters (IMPORTANT!)
    fmt.Println("\nğŸ“Š Method 3: With Parameters (Pass by Value)")
    for i := 1; i <= 3; i++ {
        wg.Add(1)
        go func(n int) {  // n is a COPY of i
            defer wg.Done()
            fmt.Printf("   Goroutine received: %d\n", n)
        }(i)  // Pass i here!
    }
    wg.Wait()
    
    // Method 4: Method as goroutine
    fmt.Println("\nğŸ“Š Method 4: Method as Goroutine")
    worker := &Worker{ID: 1}
    wg.Add(1)
    go worker.DoWork(&wg)
    wg.Wait()
    
    // Check goroutine count
    fmt.Println("\nğŸ“Š Goroutine Statistics:")
    fmt.Printf("   Active goroutines: %d\n", runtime.NumGoroutine())
    
    // Spawn many goroutines
    fmt.Println("\nğŸ“Š Spawning 10,000 Goroutines:")
    for i := 0; i < 10000; i++ {
        wg.Add(1)
        go func() {
            defer wg.Done()
            time.Sleep(10 * time.Millisecond)
        }()
    }
    fmt.Printf("   Peak goroutines: %d\n", runtime.NumGoroutine())
    wg.Wait()
    fmt.Printf("   After completion: %d\n", runtime.NumGoroutine())
}
```

**Output:**
```
(goroutine output order may vary)
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘           GOROUTINES - COMPLETE GUIDE                     â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“Š Method 1: Named Function
   Hello from named function!

ğŸ“Š Method 2: Anonymous Function
   Hello from anonymous function!

ğŸ“Š Method 3: With Parameters (Pass by Value)
   Goroutine received: 1
   Goroutine received: 2
   Goroutine received: 3

ğŸ“Š Method 4: Method as Goroutine
   Worker 1 doing work!

ğŸ“Š Goroutine Statistics:
   Active goroutines: 1

ğŸ“Š Spawning 10,000 Goroutines:
   Peak goroutines: 10001
   After completion: 1
```

func namedFunction(wg *sync.WaitGroup) {
    defer wg.Done()
    fmt.Println("   Hello from named function!")
}

type Worker struct {
    ID int
}

func (w *Worker) DoWork(wg *sync.WaitGroup) {
    defer wg.Done()
    fmt.Printf("   Worker %d doing work!\n", w.ID)
}
```

---

## âš ï¸ Goroutine Gotchas (Detailed)

```go
// goroutine_gotchas.go
package main

import (
    "fmt"
    "sync"
    "time"
)

func main() {
    fmt.Println("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
    fmt.Println("â•‘           GOROUTINE GOTCHAS - DETAILED                    â•‘")
    fmt.Println("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
    
    // GOTCHA 1: Loop variable capture
    fmt.Println("\nâŒ GOTCHA 1: Loop Variable Capture")
    fmt.Println("   The Classic Bug:")
    
    var wg sync.WaitGroup
    values := []int{1, 2, 3, 4, 5}
    
    fmt.Println("\n   BAD (all print same value):")
    for _, v := range values {
        wg.Add(1)
        go func() {
            defer wg.Done()
            fmt.Printf("   value: %d\n", v)  // v is SHARED!
        }()
    }
    wg.Wait()
    
    fmt.Println("\n   GOOD (pass as parameter):")
    for _, v := range values {
        wg.Add(1)
        go func(val int) {  // val is a COPY
            defer wg.Done()
            fmt.Printf("   value: %d\n", val)
        }(v)  // Pass v here
    }
    wg.Wait()
    
    fmt.Println("\n   ALSO GOOD (shadow variable - Go 1.22+ default):")
    for _, v := range values {
        v := v  // Shadow - creates new variable each iteration
        wg.Add(1)
        go func() {
            defer wg.Done()
            fmt.Printf("   value: %d\n", v)
        }()
    }
    wg.Wait()
    
    // GOTCHA 2: Main exits, goroutines die
    fmt.Println("\nâŒ GOTCHA 2: Main Exits = Goroutines Die")
    fmt.Println("   func main() {")
    fmt.Println("       go doWork()  // May NEVER run!")
    fmt.Println("   }  // main exits immediately")
    fmt.Println("")
    fmt.Println("   FIX: Use WaitGroup, channels, or select{}")
    
    // GOTCHA 3: Goroutine leak
    fmt.Println("\nâŒ GOTCHA 3: Goroutine Leak")
    fmt.Println("   ch := make(chan int)")
    fmt.Println("   go func() {")
    fmt.Println("       val := <-ch  // Blocks forever if nothing sent!")
    fmt.Println("   }()")
    fmt.Println("   // Forgot to send or close ch - goroutine leaks!")
    fmt.Println("")
    fmt.Println("   FIX: Always ensure goroutines can exit")
    fmt.Println("        Use context for cancellation")
    
    // GOTCHA 4: Data race
    fmt.Println("\nâŒ GOTCHA 4: Data Race")
    fmt.Println("   counter := 0")
    fmt.Println("   for i := 0; i < 1000; i++ {")
    fmt.Println("       go func() { counter++ }()  // RACE!")
    fmt.Println("   }")
    fmt.Println("")
    fmt.Println("   FIX: Use sync.Mutex, sync/atomic, or channels")
    fmt.Println("   DETECT: Run with 'go run -race program.go'")
    
    // GOTCHA 5: Panic in goroutine crashes everything
    fmt.Println("\nâŒ GOTCHA 5: Panic in Goroutine")
    fmt.Println("   go func() {")
    fmt.Println("       panic(\"oops\")  // Crashes ENTIRE program!")
    fmt.Println("   }()")
    fmt.Println("")
    fmt.Println("   FIX: Use recover in deferred function:")
    fmt.Println("   go func() {")
    fmt.Println("       defer func() {")
    fmt.Println("           if r := recover(); r != nil {")
    fmt.Println("               log.Printf(\"Recovered: %v\", r)")
    fmt.Println("           }")
    fmt.Println("       }()")
    fmt.Println("       // risky code here")
    fmt.Println("   }()")
}
```

**Output:**
```
(goroutine output order may vary)
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘           GOROUTINE GOTCHAS - DETAILED                    â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

âŒ GOTCHA 1: Loop Variable Capture
   The Classic Bug:

   BAD (all print same value):
   value: 5
   value: 5
   value: 5
   value: 5
   value: 5

   GOOD (pass as parameter):
   value: 1
   value: 2
   value: 3
   value: 4
   value: 5

   ALSO GOOD (shadow variable - Go 1.22+ default):
   value: 1
   value: 2
   value: 3
   value: 4
   value: 5

âŒ GOTCHA 2: Main Exits = Goroutines Die
   func main() {
       go doWork()  // May NEVER run!
   }  // main exits immediately

   FIX: Use WaitGroup, channels, or select{}

âŒ GOTCHA 3: Goroutine Leak
   ch := make(chan int)
   go func() {
       val := <-ch  // Blocks forever if nothing sent!
   }()
   // Forgot to send or close ch - goroutine leaks!

   FIX: Always ensure goroutines can exit
        Use context for cancellation

âŒ GOTCHA 4: Data Race
   counter := 0
   for i := 0; i < 1000; i++ {
       go func() { counter++ }()  // RACE!
   }

   FIX: Use sync.Mutex, sync/atomic, or channels
   DETECT: Run with 'go run -race program.go'

âŒ GOTCHA 5: Panic in Goroutine
   go func() {
       panic("oops")  // Crashes ENTIRE program!
   }()

   FIX: Use recover in deferred function:
   go func() {
       defer func() {
           if r := recover(); r != nil {
               log.Printf("Recovered: %v", r)
           }
       }()
       // risky code here
   }()
```

---

## ğŸ”„ sync.WaitGroup In-Depth

```go
// waitgroup_indepth.go
package main

import (
    "fmt"
    "sync"
    "time"
)

func main() {
    fmt.Println("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
    fmt.Println("â•‘           WAITGROUP - IN DEPTH                            â•‘")
    fmt.Println("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
    
    var wg sync.WaitGroup
    
    // Basic usage
    fmt.Println("\nğŸ“Š Basic WaitGroup Pattern:")
    for i := 1; i <= 3; i++ {
        wg.Add(1)  // BEFORE launching goroutine!
        go func(id int) {
            defer wg.Done()  // ALWAYS use defer
            fmt.Printf("   Worker %d starting\n", id)
            time.Sleep(time.Duration(id*50) * time.Millisecond)
            fmt.Printf("   Worker %d done\n", id)
        }(i)
    }
    wg.Wait()  // Block until counter = 0
    fmt.Println("   All workers completed!")
    
    // Common mistake: Add inside goroutine
    fmt.Println("\nâš ï¸ Common Mistake:")
    fmt.Println("   // WRONG!")
    fmt.Println("   go func() {")
    fmt.Println("       wg.Add(1)  // Race condition!")
    fmt.Println("       defer wg.Done()")
    fmt.Println("   }()")
    fmt.Println("")
    fmt.Println("   // RIGHT!")
    fmt.Println("   wg.Add(1)  // Add BEFORE go")
    fmt.Println("   go func() {")
    fmt.Println("       defer wg.Done()")
    fmt.Println("   }()")
    
    // Add with count
    fmt.Println("\nğŸ“Š Add with Count:")
    numWorkers := 5
    wg.Add(numWorkers)  // Add all at once
    for i := 0; i < numWorkers; i++ {
        go func(id int) {
            defer wg.Done()
            fmt.Printf("   Worker %d\n", id)
        }(i)
    }
    wg.Wait()
    
    // WaitGroup is not reusable while waiting
    fmt.Println("\nğŸ“Š WaitGroup Lifecycle:")
    fmt.Println("   â€¢ Can reuse after Wait() returns")
    fmt.Println("   â€¢ Cannot Add() while Wait() is blocking")
    fmt.Println("   â€¢ counter must reach 0 for Wait() to return")
}
```

**Output:**
```
(goroutine output order may vary)
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘           WAITGROUP - IN DEPTH                            â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“Š Basic WaitGroup Pattern:
   Worker 1 starting
   Worker 2 starting
   Worker 3 starting
   Worker 1 done
   Worker 2 done
   Worker 3 done
   All workers completed!

âš ï¸ Common Mistake:
   // WRONG!
   go func() {
       wg.Add(1)  // Race condition!
       defer wg.Done()
   }()

   // RIGHT!
   wg.Add(1)  // Add BEFORE go
   go func() {
       defer wg.Done()
   }()

ğŸ“Š Add with Count:
   Worker 0
   Worker 1
   Worker 2
   Worker 3
   Worker 4

ğŸ“Š WaitGroup Lifecycle:
   â€¢ Can reuse after Wait() returns
   â€¢ Cannot Add() while Wait() is blocking
   â€¢ counter must reach 0 for Wait() to return
```

---

## ğŸï¸ Race Condition Detection

```go
// race_detection.go
package main

import (
    "fmt"
    "sync"
)

func main() {
    fmt.Println("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
    fmt.Println("â•‘           RACE CONDITION DETECTION                        â•‘")
    fmt.Println("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
    
    fmt.Println("\nğŸ“Š What is a Data Race?")
    fmt.Println("   When two goroutines access the same memory")
    fmt.Println("   AND at least one is a write")
    fmt.Println("   AND they're not synchronized")
    
    fmt.Println("\nğŸ“Š Race Detector:")
    fmt.Println("   go run -race program.go")
    fmt.Println("   go test -race ./...")
    fmt.Println("   go build -race program.go")
    
    fmt.Println("\nâŒ Example Race Condition:")
    racyCounter()
    
    fmt.Println("\nâœ… Fixed with Mutex:")
    safeCounter()
    
    fmt.Println("\nâœ… Fixed with Atomic:")
    atomicCounter()
    
    fmt.Println("\nâœ… Fixed with Channel:")
    channelCounter()
}

func racyCounter() {
    counter := 0
    var wg sync.WaitGroup
    
    for i := 0; i < 1000; i++ {
        wg.Add(1)
        go func() {
            defer wg.Done()
            counter++  // DATA RACE!
        }()
    }
    wg.Wait()
    fmt.Printf("   Racy result: %d (should be 1000)\n", counter)
}

func safeCounter() {
    counter := 0
    var mu sync.Mutex
    var wg sync.WaitGroup
    
    for i := 0; i < 1000; i++ {
        wg.Add(1)
        go func() {
            defer wg.Done()
            mu.Lock()
            counter++
            mu.Unlock()
        }()
    }
    wg.Wait()
    fmt.Printf("   Mutex result: %d\n", counter)
}

func atomicCounter() {
    // Using sync/atomic
    fmt.Println("   (See sync/atomic examples in sync package file)")
}

func channelCounter() {
    counter := 0
    done := make(chan bool)
    increment := make(chan bool)
    
    // Counter goroutine (single owner)
    go func() {
        for range increment {
            counter++
        }
        done <- true
    }()
    
    // Send 1000 increments
    var wg sync.WaitGroup
    for i := 0; i < 1000; i++ {
        wg.Add(1)
        go func() {
            defer wg.Done()
            increment <- true
        }()
    }
    wg.Wait()
    close(increment)
    <-done
    
    fmt.Printf("   Channel result: %d\n", counter)
}
```

**Output:**
```
(goroutine output order may vary)
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘           RACE CONDITION DETECTION                        â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“Š What is a Data Race?
   When two goroutines access the same memory
   AND at least one is a write
   AND they're not synchronized

ğŸ“Š Race Detector:
   go run -race program.go
   go test -race ./...
   go build -race program.go

âŒ Example Race Condition:
   Racy result: 987 (should be 1000)

âœ… Fixed with Mutex:
   Mutex result: 1000

âœ… Fixed with Atomic:
   (See sync/atomic examples in sync package file)

âœ… Fixed with Channel:
   Channel result: 1000
```

---

## ğŸ†š Java Comparison

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                 â”‚
â”‚  JAVA                              GO                           â”‚
â”‚                                                                 â”‚
â”‚  new Thread(() -> {                go func() {                  â”‚
â”‚      doWork();                         doWork()                 â”‚
â”‚  }).start();                       }()                          â”‚
â”‚                                                                 â”‚
â”‚  ExecutorService pool =            // Just use goroutines!      â”‚
â”‚    Executors.newFixedThreadPool(n) // Go runtime handles it     â”‚
â”‚                                                                 â”‚
â”‚  synchronized (lock) {             mu.Lock()                    â”‚
â”‚      // critical section           // critical section          â”‚
â”‚  }                                 mu.Unlock()                  â”‚
â”‚                                                                 â”‚
â”‚  thread.join();                    wg.Wait()                    â”‚
â”‚                                                                 â”‚
â”‚  // 10,000 threads = ~80GB RAM     // 1,000,000 goroutines      â”‚
â”‚  // and very slow                  // = ~2GB RAM and fast       â”‚
â”‚                                                                 â”‚
â”‚  Thread.currentThread()            runtime.NumGoroutine()       â”‚
â”‚                                                                 â”‚
â”‚  Runtime.getRuntime()              runtime.GOMAXPROCS()         â”‚
â”‚    .availableProcessors()          runtime.NumCPU()             â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ¯ Key Takeaways

1. **Concurrency â‰  Parallelism** - structure vs execution
2. **Goroutines are cheap** - 2KB stack, create millions
3. **GMP Model** - Go schedules G on M via P
4. **GOMAXPROCS** - controls max parallel execution (default = CPU cores)
5. **Always use WaitGroup** or channels to synchronize
6. **Pass loop variables** as parameters to avoid capture bugs
7. **Use `go run -race`** to detect data races
8. **Main exits = goroutines die** - ensure proper synchronization

---

## â¡ï¸ Next Steps

**Next Topic:** [30 - Channels](./30-channels.md)
